{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray framework\n",
    "\n",
    "## Obsah\n",
    "- [Úvod](#1)\n",
    "- [Obecně o Ray framework](#2)\n",
    "- [Cluster - obecně](#3)\n",
    "- [Ray Cluster](#4)\n",
    "    - [Head node](#5)\n",
    "    - [Worker nodes](#6)\n",
    "- [Ray framework z pohledu vývojáře Python aplikací](#7)\n",
    "    - [Ray Core](#8)\n",
    "    - [Připojení k existujícímu clusteru](#9)\n",
    "    - [Poznámka k Ray na Windows](#10)\n",
    "    - [Vzdálený cluster](#11)\n",
    "- [Ray Framework z pohledu infrastruktury](#12)\n",
    "- [Praktická ukázka](#13)\n",
    "    - [Tvorba clusteru](#14)\n",
    "        - [Příprava infrastruktury](#15)\n",
    "        - [Instalace Ray a spuštění clusteru](#16)\n",
    "        - [Řešené problémy](#17)\n",
    "            - [Vzdálený vývoj](#18)\n",
    "            - [Přidání Ray do PATH](#19)\n",
    "    - [AI](#20)\n",
    "        - [Úprava kódu pro distribuovanou AI](#21)\n",
    "    - [Trénink AI v clusteru](#22)\n",
    "- [Závěr](#23)\n",
    "- [Zdroje](#24)\n",
    "\n",
    "<a id=\"1\"></a>\n",
    "# Úvod\n",
    "- cílem tohoto notebooku je seznámit s praktickým nasazením distribuované AI\n",
    "- k dosažení tohoto cíle je potřeba pochopit základní principy fungování poskytovaného frameworku\n",
    "\n",
    "- tento notebook bych rád rozdělil na tři části:\n",
    "    1. [Ray framework z pohledu vývojáře Python aplikací](#7)\n",
    "        - tato část bude sloužit pro pochopení změn v kódu aplikace (AI), které byly nezbytné, aby AI mohla být distibuovaná\n",
    "        - tzn. mám k dispozici cluster a starám se jen o psaní kódu, využívám služeb clusteru\n",
    "    2. [Ray Framework z pohledu infrastruktury](#12)\n",
    "        - tato část bude sloužit pro získání dovedností nutných k vybudování vlasního malého clusteru\n",
    "        - tzn. chci vybudovat a spravovat svůj cluster a poskytovat ho pro vývojáře\n",
    "    3. [Praktická ukázka](#13)\n",
    "        - nasazení distribuované AI na vytvořený cluster\n",
    "\n",
    "<a id=\"2\"></a>\n",
    "# Obecně o Ray Framework\n",
    "- jedná se o nástroj který slouží ke škálování aplikací\n",
    "- hlavní myšlenkou je možnost škálování aplikace \"from laptop to datacentre with little to no code changes\"\n",
    "- postupně se rozrostl na několik součástí:\n",
    "    - Ray Core\n",
    "    - Ray Clusters\n",
    "    - Ray Data\n",
    "    - Ray Train\n",
    "    - Ray Tune\n",
    "    - Ray Serve\n",
    "    - Ray RLlib\n",
    "\n",
    "<a id=\"3\"></a>\n",
    "# Cluster - obecně\n",
    "- computer cluster is a set of computers (nodes) that work together so that they can be viewed as a single system __[(zdroj)](https://en.wikipedia.org/wiki/Computer_cluster)__\n",
    "- obvykle se skládá z control node a compute nodes\n",
    "- control node řídí celý cluster, přiděluje úlohy a stará se o komunikaci s uživatelem\n",
    "- compute nodes vykonávají výpočty a výsledky předávají do control node\n",
    "- z pohledu uživatele clusteru tak předáváme úlohu k výpočtu jednomu počítači (control node) - nestaráme se o vnitřní fungování clusteru (distribuci na compute nodes)\n",
    "\n",
    "<a id=\"4\"></a>\n",
    "# Ray Cluster\n",
    "- Ray framework pracuje s výše popsaným konceptem clusteru, jen používá mírně jinou terminologii pro nodes\n",
    "- rozlišuje head node (=control node) a worker node (=compute node)\n",
    "\n",
    "![Ray Cluster](pictures\\cluster.png)\n",
    "\n",
    "- počet worker nodů lze dynamicky měnit podle zátěže - tzn. lze provádět autoscaling\n",
    "- cluster bývá v praxi velmi výkonný server nebo skupina serverů, popř. VM na cloudu - Ray podporuje AWS a Azure\n",
    "- v rámci jednoho node funguje paralelizace na úrovni vláken - i na jednom nodu mohou běžet dvě a více úloh současně\n",
    "\n",
    "<a id=\"5\"></a>\n",
    "## Head node\n",
    "- každý cluster musí obsahovat head node\n",
    "- pokud spustíme Ray jen na našem zařízení (např. notebook), tak de facto vytvoříme cluster o jednom head nodu a žádných worker nodes\n",
    "- head node je téměř stejný jako worker node, jen na něm navíc běží další procesy pro obsluhu clusteru\n",
    "- je to jediný node, se kterým budeme jako uživatelé clusteru komunikovat\n",
    "\n",
    "<a id=\"6\"></a>\n",
    "## Worker nodes\n",
    "- slouží pouze ke spouštění kódu\n",
    "- sdílí mezi sebou cluster memory\n",
    "\n",
    "<a id=\"7\"></a>\n",
    "# 1. Ray framework z pohledu vývojáře Python aplikací\n",
    "- v této části nás bude nejvíce zajímat Ray Core a práce s API tzn. zajímáme se o to, jak psát programy pro Ray clustery\n",
    "\n",
    "<a id=\"8\"></a>\n",
    "# Ray Core\n",
    "- poskytuje základní entity, se kterými Ray pracuje - jedná se o tasks (odpovídá python funkcím), actors (odpovídá python instancím), objects (odpovídá python objektům)\n",
    "- je to původní a první modul celého frameworku\n",
    "- poskytuje možnost spuštění nejmenšího \"clusteru\" - clusterem je v tomto případě náš počítač na kterém běží head node\n",
    "- i v takto minimální konfiguraci lze těžit z výhod Ray Core - umí paralelizovat výpočty na jendom stroji - v rámci nodu běží více procesů\n",
    "- lze se tak odstínit od paralelizace a nechat vše na frameworku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U \"ray[default]\" #instalace Ray frameworku - tato konfigurace umožňuje jeho využití s jakoukoliv apliakací - ne jen AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- komunikaci s __lokálním__ clusterem provádíme pomocí Ray API\n",
    "- stačí nám volat funkce z knihovny ray\n",
    "- framework se postará o spuštění clusteru a odeslání úlohy na něj\n",
    "- Python funkce popř. objekty určené pro zpracování v clusteru se dekorují pomocí @ray.remote\n",
    "- při volání fcí se opět používá .remote()\n",
    "- jakmile funkci zavoláme, tak je odeslána ke zpracování do clusteru (zde se jedná jen o náš ntb = head node)\n",
    "- kód samotné aplikace pokračuje i po zavolání fce - nečeká se na její dokončení - výpočet dekorované remote fce se provádí v clusteru (v praxi by např. běžel v cloudu)\n",
    "- funkce tedy nevrací hodnotu, ale vrací pouze příslib budoucího výsledku\n",
    "- pokud chceme v aplikaci počkat na dokončení výpočtu, musíme zavolat fci ray.get() do které jako parametr vložíme future promise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\remar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-11-16 12:47:11,925\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2023-11-16 12:47:15,034\tINFO worker.py:1664 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pokracuji si klidně dál\n",
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400, 441, 484, 529, 576, 625, 676, 729, 784, 841, 900, 961, 1024, 1089, 1156, 1225, 1296, 1369, 1444, 1521, 1600, 1681, 1764, 1849, 1936, 2025, 2116, 2209, 2304, 2401, 2500, 2601, 2704, 2809, 2916, 3025, 3136, 3249, 3364, 3481, 3600, 3721, 3844, 3969, 4096, 4225, 4356, 4489, 4624, 4761, 4900, 5041, 5184, 5329, 5476, 5625, 5776, 5929, 6084, 6241, 6400, 6561, 6724, 6889, 7056, 7225, 7396, 7569, 7744, 7921, 8100, 8281, 8464, 8649, 8836, 9025, 9216, 9409, 9604, 9801]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import time\n",
    "\n",
    "@ray.remote #zde je možné specifikovat nějaké parametry spuštění např. @ray.remote(num_cpus=4)\n",
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "ray.init() # zde provedeme spuštění local head node - na něj budeme odesílat úlohy\n",
    "#start = time.time()\n",
    "\n",
    "futures = [] # připravený list na future results (= promises)\n",
    "\n",
    "for i in range(100):\n",
    "    futures.append(square.remote(i)) #futures je list příslibů - odkaz na budoucí výsledek - konkrétní výsledek dostaneme po zavolání fce ray.get()\n",
    "    # ray.get() lze volat na celý list příslibů - viz dole ray.get(futures) nebo jen na jeden záznam např. ray.get(futures[10])\n",
    "    # po zavolání get se čeká na dokončení výsledku výpočtu\n",
    "\n",
    "\n",
    "print(\"Pokracuji si klidně dál\") #program zde může pokračovat - výpočet běží v clusteru - na výsledky si počkám až když zavolám fci get\n",
    "data = ray.get(futures) #data je klasický list výsledků [0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
    "\n",
    "print(data)\n",
    "print(type(data))\n",
    "\n",
    "#print(time.time()-start)\n",
    "\n",
    "ray.shutdown() #ukončí cluster - ukončí se po skončení programu, zde ale nutné - problém v jupyter kernelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- obdobně lze v clusteru definovat i objekty - ty se v ray core definují jako actors - lze mít na clusteru objekt a pracovat s ním"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\remar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-11-16 12:48:07,156\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2023-11-16 12:48:10,229\tINFO worker.py:1664 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ray.actor.ActorHandle'>\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "@ray.remote\n",
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.i\n",
    "    \n",
    "    def incr(self, value):\n",
    "        self.i += value\n",
    "\n",
    "\n",
    "ray.init()\n",
    "\n",
    "c = Counter.remote() #jedná se pouze o actor handle - nejedná se o klasický python objekt - objekt se vytvoří na daném clusteru\n",
    "# pomocí actor handle se můžeme odkazovat na tuto instanci v clusteru\n",
    "print(type(c))\n",
    "\n",
    "for _ in range(10):\n",
    "    c.incr.remote(10) #voláme fci na instanci v clusteru\n",
    "\n",
    "print(ray.get(c.get_data.remote())) #počkáme si na výsledek fce a vypíšeme\n",
    "\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak je patrné z ukázek, tak použití ray core je velmi jednoduché a opravdu lze velmi snadno stávající kód upravit tak, aby byl připraven pro nasazení v clusteru.\n",
    "Výpočetně náročné operace tak lze snadno přenést na výkonný stroj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\remar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-11-17 12:59:12,499\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2023-11-17 12:59:17,846\tINFO worker.py:1664 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nove zpravy: []\n",
      "Nove zpravy: ['Zprava od 1 cislo 0', 'Zprava od 0 cislo 0', 'Zprava od 2 cislo 0']\n",
      "Nove zpravy: ['Zprava od 2 cislo 1', 'Zprava od 0 cislo 1', 'Zprava od 1 cislo 1']\n",
      "Nove zpravy: ['Zprava od 2 cislo 2', 'Zprava od 1 cislo 2', 'Zprava od 0 cislo 2']\n",
      "Nove zpravy: ['Zprava od 1 cislo 3', 'Zprava od 2 cislo 3', 'Zprava od 0 cislo 3']\n",
      "Nove zpravy: ['Zprava od 0 cislo 4', 'Zprava od 1 cislo 4', 'Zprava od 2 cislo 4']\n",
      "Nove zpravy: ['Zprava od 0 cislo 5', 'Zprava od 2 cislo 5', 'Zprava od 1 cislo 5']\n",
      "Nove zpravy: ['Zprava od 2 cislo 6', 'Zprava od 1 cislo 6', 'Zprava od 0 cislo 6']\n",
      "Nove zpravy: ['Zprava od 0 cislo 7', 'Zprava od 1 cislo 7', 'Zprava od 2 cislo 7']\n",
      "Nove zpravy: ['Zprava od 1 cislo 8', 'Zprava od 0 cislo 8', 'Zprava od 2 cislo 8']\n",
      "Nove zpravy: ['Zprava od 1 cislo 9', 'Zprava od 0 cislo 9', 'Zprava od 2 cislo 9']\n",
      "Nove zpravy: ['Zprava od 2 cislo 10', 'Zprava od 0 cislo 10', 'Zprava od 1 cislo 10']\n",
      "Nove zpravy: ['Zprava od 0 cislo 11', 'Zprava od 1 cislo 11', 'Zprava od 2 cislo 11']\n",
      "Nove zpravy: ['Zprava od 0 cislo 12', 'Zprava od 1 cislo 12', 'Zprava od 2 cislo 12']\n",
      "Nove zpravy: ['Zprava od 2 cislo 13', 'Zprava od 1 cislo 13', 'Zprava od 0 cislo 13']\n",
      "Nove zpravy: ['Zprava od 1 cislo 14', 'Zprava od 0 cislo 14', 'Zprava od 2 cislo 14']\n",
      "Nove zpravy: ['Zprava od 2 cislo 15', 'Zprava od 0 cislo 15', 'Zprava od 1 cislo 15']\n",
      "Nove zpravy: ['Zprava od 0 cislo 16', 'Zprava od 2 cislo 16', 'Zprava od 1 cislo 16']\n",
      "Nove zpravy: ['Zprava od 1 cislo 17', 'Zprava od 0 cislo 17', 'Zprava od 2 cislo 17']\n",
      "Nove zpravy: ['Zprava od 0 cislo 18', 'Zprava od 1 cislo 18', 'Zprava od 2 cislo 18']\n",
      "Nove zpravy: ['Zprava od 0 cislo 19', 'Zprava od 2 cislo 19', 'Zprava od 1 cislo 19']\n",
      "Nove zpravy: []\n",
      "Nove zpravy: []\n",
      "Nove zpravy: []\n",
      "Nove zpravy: []\n",
      "Nove zpravy: []\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\remar\\Desktop\\Ray\\notebook.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/remar/Desktop/Ray/notebook.ipynb#X10sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     new_messages \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39mget(message_actor\u001b[39m.\u001b[39mget_and_clear\u001b[39m.\u001b[39mremote())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/remar/Desktop/Ray/notebook.ipynb#X10sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNove zpravy: \u001b[39m\u001b[39m{\u001b[39;00mnew_messages\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/remar/Desktop/Ray/notebook.ipynb#X10sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/remar/Desktop/Ray/notebook.ipynb#X10sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m ray\u001b[39m.\u001b[39mshutdown()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import time\n",
    "\n",
    "@ray.remote\n",
    "class MessageActor: # actor určený pro sběr zpráv\n",
    "    def __init__(self):\n",
    "        self.messages = [] # list pro uložení zpráv\n",
    "\n",
    "    def add_message(self, message):\n",
    "        self.messages.append(message)\n",
    "\n",
    "    def get_and_clear(self):\n",
    "        out = self.messages\n",
    "        self.messages = []\n",
    "        return out\n",
    "    \n",
    "@ray.remote\n",
    "def worker(message_actor, worker_no): # funkce worker generuje zprávy a předává je do objektu message actor\n",
    "    for i in range(20):\n",
    "        time.sleep(1)\n",
    "        message_actor.add_message.remote(f\"Zprava od {worker_no} cislo {i}\")\n",
    "\n",
    "message_actor = MessageActor.remote()\n",
    "\n",
    "for worker_no in range(3):\n",
    "    worker.remote(message_actor, worker_no)\n",
    "\n",
    "for _ in range(100):\n",
    "    new_messages = ray.get(message_actor.get_and_clear.remote())\n",
    "    print(f\"Nove zpravy: {new_messages}\")\n",
    "    time.sleep(1)\n",
    "\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a>\n",
    "## Připojení k existujícímu clusteru\n",
    "- do teď jsme používali funkci ray.init(), která při volání bez parametrů nejprve hledá již existující cluster a pokud ho nenajde, tak si vytvoří nový\n",
    "- obvykle budeme používat již spuštěný a existující cluster\n",
    "- pro studijní účely si můžeme toto simulovat pomocí spuštění head node z příkazové řádky - head node poběží pořád a bude jen čekat na úlohy\n",
    "- pro spuštění a správu ray nodes na našem stroji je možné použít tyto příkazy (stejné pro Win/Linux):\n",
    "    - ray start --head \n",
    "    - ray status\n",
    "    - ray stop\n",
    "\n",
    "<a id=\"10\"></a>\n",
    "## Poznámka k Ray na Windows\n",
    "- v době psaní tohoto notebooku Ray cluster plně nepodporuje Windows - pod tímto OS lze pouze spustit head node - nelze přiřadit Windows stanici jako worker do již existujícího clusteru a ani není možné k head node běžícím pod Windows připojit jakékoliv další worker nodes\n",
    "- pro studijní/testovací účely je ale head node dostatečný a lze si na něm vyzkoušet práci s Ray frameworkem\n",
    "\n",
    "## Prakticky\n",
    "Windows cmd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "ray start -- head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(address=\"auto\") # provede automatickou detekci běžících clusterů - pokud žádný nenajde -> error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- takto spuštěný cluster nám na localhost:8265 poskytuje dashboard\n",
    "- pokud head node neběží pod Windows, tak k němu lze připojovat worker nodes a budovat tak cluster\n",
    "\n",
    "<a id=\"11\"></a>\n",
    "## Vzdálený cluster\n",
    "- pokud pracujeme na stroji, který není součástí clusteru - lze pomocí Ray spustit vzdáleně úlohu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.job_submission import JobSubmissionClient\n",
    "\n",
    "client = JobSubmissionClient(\"http://192.168.88.240:8265\")\n",
    "job_id = client.submit_job(\n",
    "    # Entrypoint shell command to execute\n",
    "    entrypoint=\"python3 /home/user/Ray_test/task.py\"\n",
    "    # Path to the local directory that contains the script.py file\n",
    ")\n",
    "print(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"12\"></a>\n",
    "# 2. Ray Framework z pohledu infrastruktury\n",
    "- vlastní Ray cluster lze vytvořit na:\n",
    "    - Kubernetes\n",
    "    - AWS, GCP, Azure, vSphere\n",
    "    - Virtual machines\n",
    "- nejjednodušší a uživatelsky nejlepší mi přijde vytvářet clutery v cloudu - výborné propojení s AWS - clustery pak lze jednoduše definovat pomocí .yaml - viz. __[zde](https://docs.ray.io/en/latest/cluster/vms/references/ray-cluster-configuration.html?highlight=yaml)__\n",
    "\n",
    "- protože nemám přístup k cloudovým zdrojům, tak jsem se rozhodl vyzkoušet si nasazení Ray na VM\n",
    "\n",
    "<a id=\"13\"></a>\n",
    "# 3. Praktická ukázka\n",
    "- cílem je prakticky předvést distribuovanou AI na vlastním clusteru, který bude vytvořen pomocí virtuálních počítačů\n",
    "\n",
    "<a id=\"14\"></a>\n",
    "## Tvorba clusteru\n",
    "- rozhodl jsem se vyvtvořit si malý virtuální cluster o jednom head node a jednom worker node\n",
    "- z důvodu nekompatibility Ray s Windows bylo butné si vytvořit dva virtuální servery s Ubuntu server\n",
    "\n",
    "<a id=\"15\"></a>\n",
    "### Příprava infrastruktury\n",
    "- rozhodl jsem se použít virtulizační nástroj virtualbox, ve kterém jsem si do VM nainstaloval Ubuntu 22.04 server\n",
    "- do VM jsem nainstaloval Python 3.10 a pip\n",
    "- takto připravenou VM jsem si naklonoval\n",
    "- u klonu jsem změnil MAC adresu jeho adaptéru, hostname a ip adresu\n",
    "- oba servery jsem dal na stejnou virtuální síť spolu s host PC\n",
    "- vznikla tak tato topologie:\n",
    "![Topologie](pictures\\topologie.png)\n",
    "\n",
    "<a id=\"16\"></a>\n",
    "### Instalace Ray a spuštění clusteru\n",
    " - na obou strojích jsem provedl instalaci Ray frameworku - jak default verzi pro obecný vývoj, tak i rozšířené knihovny pro AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U \"ray[default]\"\n",
    "pip install -U \"ray[data,train,tune,serve]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nyní je možné spustit cluster\n",
    "- začneme s head node, který spustíme pomocí příkazu"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ray start --head --include-dashboard 1 --dashboard-host 0.0.0.0 --node-ip-address 192.168.88.240 --port 6379"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- přidáním parametru --dashboard-host 0.0.0.0 zpřístupníme dashboard na všech IP adresách, které server má (ne jen localhost) - můžeme si dashboard zobrazit z host pc\n",
    "- worker node spustíme a připojíme na head node pomocí příkazu"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ray start --address='192.168.88.240:6379'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- takto spuštěný cluster nám na  192.168.88.240:8265 poskytuje dashboard, kde v záložce cluster můžeme vidět, že se nám podařilo vytvořit cluster o dvou nodech\n",
    "- pokud tedy nyní na počítači raynode spustíme některý z předchozích ukázkových kódu, tak se výpočet provede na clusteru - bude ho provádět i worker node\n",
    "\n",
    "<a id=\"17\"></a>\n",
    "### Řešené problémy\n",
    "\n",
    "<a id=\"18\"></a>\n",
    "Vzdálený vývoj\n",
    "- v této fázi projektu jsem se dostal do situace, kdy jsem chtěl s clusterem nějak pohodlně pracovat\n",
    "- chtěl jsem docílit toho, že budu vyvíjet aplikaci na svém pc (v tomto případě na host pc) a úlohy se budou provádět v clusteru\n",
    "- díky tomu, že používám Windows, tak nebylo možné můj host pc přidat do clusteru - nedařilo se mi pohodlně spouštět úlohy\n",
    "- zkoušel jsem tedy různě \"ohýbat\" ray.init __[(docs)](https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html)__ tak, aby se mi podařilo odesílat úlohy na cluster rovnou z python kódu\n",
    "- vyzkoušel jsem různá řešení, včetně zrcadlení portů mého pc do portů head nodu atd.\n",
    "- žádné ze zkoušených řešení ale nepřineslo očekávaný efekt a pohodlí při vývoji\n",
    "- jako jediné řešení se jevilo napsat aplikaci, přenést ji do head node a tam ji z command line spustit, popř. používat vzdálené spouštění kódu pomocí job submission __[(docs)](https://docs.ray.io/en/latest/cluster/running-applications/job-submission/doc/ray.job_submission.JobSubmissionClient.submit_job.html)__\n",
    "- nakonec jsem se rozhodl použít modul remote-ssh, který lze nainstalovat do VS code - tento modul poskytuje možnost vzdáleného vývoje přes SSH - VS code se tváří, jako by aplikace běžela lokálně, ale ve skutečnosti běží na head node\n",
    "\n",
    "<a id=\"19\"></a>\n",
    "Přidání Ray do PATH\n",
    "- po instalaci se Ray framework nepřidal do PATH v systému Ubuntu\n",
    "- bylo nutné spouštět ray pomocí úplné cesty, např:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "/home/user/.local/bin/ray start --head --dashboard-host=192.168.88.180 --port=6379"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- podle __[návodu](https://phoenixnap.com/kb/linux-add-to-path)__ bylo nutné přidat Ray do PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"20\"></a>\n",
    "## AI\n",
    "- jako ilustrační AI jsem vybral Iris AI, kterou jsem si půjčil __[zde](https://github.com/hrbolek/learning/blob/master/notebooks/ais/58_.ipynb)__\n",
    "- AI jsem si nejprve upravil tak, abych mohl provést trénování modelu klasicky na svém stroji bez Ray framework\n",
    "- jedná se o zcela běžné použití knihovny PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "def namedata(data):\n",
    "    return {\n",
    "        'sepal_l': data[0],\n",
    "        'sepal_w': data[1],\n",
    "        'petal_l': data[2],\n",
    "        'petal_w': data[3]\n",
    "    }\n",
    "table = list(map(namedata, iris.data))\n",
    "\n",
    "tmap = {0: 'Iris-setosa', 1: 'Iris-versicolor', 2: 'Iris-virginica'}\n",
    "targets = list(map(lambda item: tmap[item], iris.target))\n",
    "table = [{**row, 'species': name} for row, name in zip(table, targets)]\n",
    "\n",
    "df = pd.DataFrame(table)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "x = df[[\"sepal_l\", \"sepal_w\", \"petal_l\", \"petal_w\"]].values\n",
    "y = le.fit_transform(df[\"species\"])\n",
    "\n",
    "species = le.classes_\n",
    "\n",
    "x = torch.tensor(x, device=device, dtype=torch.float32)\n",
    "y = torch.tensor(y, device=device, dtype=torch.long)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(x.shape[1], 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 25),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(25, len(species)),\n",
    "    nn.LogSoftmax(dim=1),\n",
    ")\n",
    "\n",
    "model = torch.compile(model,backend=\"aot_eager\").to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # cross entropy loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x)\n",
    "    # Note: CrossEntropyLoss combines nn.LogSoftmax() and nn.NLLLoss() so don't use Softmax in the model\n",
    "    loss = criterion(out, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- počet epoch učení jsem uměle zvýšil - je to jen z důvodu zvýšení náročnosti procesu učení\n",
    "\n",
    "<a id=\"21\"></a>\n",
    "## Úprava kódu pro distribuovanou AI\n",
    "- nyní jsem podle __[dokumentace](https://docs.ray.io/en/latest/train/getting-started-pytorch.html)__ upravil AI tak, aby mohla fungoval s modulem Ray train:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import ray\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import ScalingConfig, Checkpoint, report\n",
    "from ray.train.torch import prepare_model\n",
    "from ray.train.torch import prepare_data_loader\n",
    "\n",
    "def train_func(config):\n",
    "    device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "    iris = datasets.load_iris()\n",
    "    def namedata(data):\n",
    "        return {\n",
    "            'sepal_l': data[0],\n",
    "            'sepal_w': data[1],\n",
    "            'petal_l': data[2],\n",
    "            'petal_w': data[3]\n",
    "        }\n",
    "    table = list(map(namedata, iris.data))\n",
    "\n",
    "    tmap = {0: 'Iris-setosa', 1: 'Iris-versicolor', 2: 'Iris-virginica'}\n",
    "    targets = list(map(lambda item: tmap[item], iris.target))\n",
    "    table = [{**row, 'species': name} for row, name in zip(table, targets)]\n",
    "\n",
    "    df = pd.DataFrame(table)\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "\n",
    "    x = df[[\"sepal_l\", \"sepal_w\", \"petal_l\", \"petal_w\"]].values\n",
    "    y = le.fit_transform(df[\"species\"])\n",
    "\n",
    "    species = le.classes_\n",
    "\n",
    "    x = torch.tensor(x, device=device, dtype=torch.float32)\n",
    "    y = torch.tensor(y, device=device, dtype=torch.long)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(x.shape[1], 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, 25),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(25, len(species)),\n",
    "        nn.LogSoftmax(dim=1),\n",
    "    )\n",
    "\n",
    "    #model = torch.compile(model,backend=\"aot_eager\").to(device)\n",
    "    model = prepare_model(model)\n",
    "    criterion = nn.CrossEntropyLoss()  # cross entropy loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    #train_loader = prepare_data_loader(train_loader)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(1000):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        # Note: CrossEntropyLoss combines nn.LogSoftmax() and nn.NLLLoss() so don't use Softmax in the model\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        report({\"loss\": loss.item()})\n",
    "            \n",
    "ray.init(address=\"auto\")\n",
    "scaling_config = ScalingConfig(num_workers=7, use_gpu=False) #zde si cluster žádám o resources - můj cluster má 8cpus - lze požádat o 7 workers (1 cpu je head)\n",
    "trainer = TorchTrainer(train_func, scaling_config=scaling_config)\n",
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- jak je patrné z kódu pro distibuované učení AI, tak je možné definovat si pro danou úlohu resources - tzn. lze si cluster požádat o přidělení konkrétních zdrojů pro provedení výpočtu\n",
    "- protože jsem virtualizaci clusteru prováděl na svém notebooku pomocí nástroje virtualbox, tak se mi nepodařilo spustit oba servery najednou tak, aby měly přístup k gpu - z toho důvodu jsem nechal výpočty běžet jen na cpu -> parametr use_gpu=False\n",
    "- pro spuštění AI v mém clusteru bylo potřeba do obou serverů nainstalovat potřebné dependencies:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install scikit-learn\n",
    "pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"22\"></a>\n",
    "# Trénink AI v clusteru\n",
    "- po spuštění úlohy na head node je možné během učení neuronové sítě sledovat zvýšenou zátěž obou serverů - tzn. došlo k distribuci učení AI na celý cluster - v našem případě na head a worker node\n",
    "- takto natrénovaný model lze dále používat - lze ho nechat na clusteru a jen do něj posílat úlohy\n",
    "\n",
    "<a id=\"23\"></a>\n",
    "# Závěr\n",
    "Ray framework je silný nástroj pro paralelizaci úloh a tvorbu clusterů. Poskytuje mnoho dalších nástrojů a knihoven, které pokrývají celý životní cyklus vývoje AI - od zpracování dat přes trénink, ladění modelu až po poskytnutí modelu. Vývojář je tak zcela odstíněn od paralelizace výpočtů a framework podle mě skutečně naplňuje své odvážné marketingové tvrzení \"from laptop to datacentre with little to no code changes\".\n",
    "\n",
    "Důkazem může být i použití Ray clusterů při učení neuronové sítě pro chat-gpt.\n",
    "\n",
    "<a id=\"24\"></a>\n",
    "# Zdroje\n",
    "\n",
    "- https://medium.com/juniper-team/tips-on-installing-and-maintaining-ray-cluster-b5535743f97c\n",
    "- https://saturncloud.io/blog/getting-started-with-ray-clusters/\n",
    "- https://docs.ray.io/en/latest/cluster/vms/references/ray-cluster-configuration.html?highlight=yaml\n",
    "- https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html\n",
    "- https://medium.com/@fengliplatform/ray-quick-hands-on-ecf744eb304f\n",
    "- https://docs.ray.io/en/latest/train/getting-started-pytorch.html\n",
    "- https://docs.ray.io/en/latest/cluster/running-applications/job-submission/sdk.html#ray-job-sdk\n",
    "- https://docs.ray.io/en/latest/ray-overview/installation.html\n",
    "- https://docs.ray.io/en/latest/cluster/running-applications/job-submission/doc/ray.job_submission.JobSubmissionClient.submit_job.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
